#Raft Based Distributed cache
基于Raft论文实现的,github有个中文的[Raft中文翻译版本](https://github.com/maemual/raft-zh_cn)<br>
翻译的很准,不过感觉还是英文的比较好,英文的读的慢思考时间更多。<br>
学习用的应该有bug的,包括查资料,写代码,测试用了大概十多天的样子吧<br>
整体思路就是由Raft算法维持集群状态的一致性（节点丢失，增加问题）
一致性hash将数据分散到各个节点上(搞不懂为啥很多做缓存的,还要让集群缓存数据一致,个人感觉缓存的系统压力主要在内存上，其次才是客户端连接的压力)


# 支持的功能
* leader选举
* 集群成员动态更变,保证集群半数以上server活着,依然能对外提供服务
* 基于一致性hash保证缓存数据的负载均衡
* 客户端连接server基于随机算法,保证每台server连接的client负载均衡
* 缓存数据的备份(内存快照+写操作的日志 = 完整缓存数据)


#技术点
* Raft算法
* 一致性hash
* java NIO(处理客户端请求是基于nio) 
* 并发编程


#Quick Start
* ./build.sh 5    可以快速在本机上部署五个实例的集群(必须写正常的参数,shell脚本不太会,没处理异常的)
* ./kill_all.sh 5 可以关闭这五台集群(必须正确的参数)
* ./kill.sh 1     可以关闭id = 1 的一个实例(必须正确的参数)
* ./client.sh 127.0.0.1:9091 可以连接集群中指定实例，不写参数的的话会随机选择一台
* 反复创建(执行build.sh) 而没有对应关掉的话,自己jps 查看下手动kill
* build.sh 之后一定要有kill，才能再build,pid文件存在创建实例的时候会自己退出

#程序运行流程



#总结(遇到的坑)
* lock.lock() 一定要在finally里面unlock 释放锁，状态转换的时候可能会中断该线程，导致锁没有释放
    最后其他线程无限等待状态
* lock 里面不要放io这种耗时操作，io 阻塞后的线程切换并不会释放锁，切换别的线程拿不到锁，也是白搞
* 本来是用map维护socket连接的，最后自己粗心了，创建socket之后没有put进去,导致监听该socket连接的server
    创建过多连接，导致线程池线程耗完，无法处理后续连接
* 考虑所有的情况，不要在编码的时候合并流程（即使该流程是不会发生的）,可以在编码完成后再合并
* NIO这块网上的demo基本没有能直接跑的,cpu跑满的,不管数据有多大，直接往buffer里面扔,发送给客户端也有
* 心跳时间间隔没调好，算法收敛没那么快(启动的时候或者leader挂了，手速快的话可以在client那边看到)


